{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense,Embedding\n",
    "from keras.layers import LSTM,Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import fasttext\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          image_name                                           text_ocr  \\\n",
      "0        image_1.jpg  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   \n",
      "1       image_2.jpeg  The best of #10 YearChallenge! Completed in le...   \n",
      "2        image_3.JPG  Sam Thorne @Strippin ( Follow Follow Saw every...   \n",
      "3        image_4.png              10 Year Challenge - Sweet Dee Edition   \n",
      "4        image_5.png  10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...   \n",
      "...              ...                                                ...   \n",
      "6987  image_6988.jpg  Tuesday is Mardi Gras Wednesday is Valentine's...   \n",
      "6988  image_6989.jpg  MUST WATCH MOVIES OF 2017 ITI Chennai memes MA...   \n",
      "6989  image_6990.png  LESS MORE TALKING PLANNING SODA JUNK FOOD COMP...   \n",
      "6990  image_6991.jpg  When I VERY have time is a fantasy No one has ...   \n",
      "6991  image_6992.jpg  The starting point for every good idea is \"Wha...   \n",
      "\n",
      "                                         text_corrected       offensive  \n",
      "0     look there my friend lightyear now all sohalik...   not_offensive  \n",
      "1     the best of #10 yearchallenge! completed in le...   not_offensive  \n",
      "2     sam thorne @strippin ( follow follow saw every...   not_offensive  \n",
      "3                 10 year challenge - sweet dee edition  very_offensive  \n",
      "4     10 year challenge with no filter 47 hilarious ...  very_offensive  \n",
      "...                                                 ...             ...  \n",
      "6987  tuesday is mardi gras wednesday is valentine's...  very_offensive  \n",
      "6988  must watch movies of 2017 iti chennai memes ma...   not_offensive  \n",
      "6989  less more talking planning soda junk food comp...          slight  \n",
      "6990  when i have time is a fantasy. no one has time...   not_offensive  \n",
      "6991  the starting point for every good idea is \"wha...   not_offensive  \n",
      "\n",
      "[6992 rows x 4 columns]\n",
      "(6992, 4)\n"
     ]
    }
   ],
   "source": [
    "#Cleaning\n",
    "data=pd.read_csv('offensiveMemes.csv')\n",
    "data.text_corrected=data.text_corrected.astype(str)\n",
    "data[\"text_corrected\"]= data[\"text_corrected\"].str.lower() \n",
    "print(data)\n",
    "\n",
    "data=data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(data.shape)\n",
    "data['text_corrected'] = data['text_corrected'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]', '', x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/askvyas/Documents/Memology/final.txt\n"
     ]
    }
   ],
   "source": [
    "data_f=pd.DataFrame(data, columns = ['text_corrected', 'offensive'])\n",
    "\n",
    "data_f = data_f.rename(columns={\"text_corrected\":\"text\", \"offensive\":\"label\"})\n",
    "\n",
    "\n",
    "data_f['label'] = '__label__' + data_f['label'].astype(str)\n",
    "data_f.to_csv('final.txt', sep='\\t', index = False, header = False)\n",
    "\n",
    "\n",
    "training_data_path=os.getcwd()+'/final.txt'\n",
    "print(training_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/askvyas/Documents/Memology/valid.txt\n"
     ]
    }
   ],
   "source": [
    "a=data_f[data_f['label']=='__label__not_offensive']\n",
    "b=data_f[data_f['label']=='__label__very_offensive']\n",
    "c=data_f[data_f['label']=='__label__slight']\n",
    "d=data_f[data_f['label']=='__label__hateful_offensive']\n",
    "\n",
    "\n",
    "data_v=a.sample(200)\n",
    "data_v=data_v.append(b.sample(200))\n",
    "data_v=data_v.append(c.sample(200))\n",
    "data_v=data_v.append(d.sample(200))\n",
    "data_v.to_csv('valid.txt', sep='\\t', index = False, header = False)\n",
    "validation_data_path=os.getcwd()+'/valid.txt'\n",
    "print(validation_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {\"lr\": 0.01,\n",
    "                        \"epoch\": 20,\n",
    "                        \"wordNgrams\": 2,\n",
    "                        \"dim\": 300}\n",
    "\n",
    "\n",
    "model = fasttext.train_supervised(input=training_data_path, **hyper_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.01, 'epoch': 20, 'wordNgrams': 2, 'dim': 300},accuracy:0.3880148741418764,validation:0.25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "        result = model.test(training_data_path)\n",
    "        validation = model.test(validation_data_path)\n",
    "        \n",
    "        # DISPLAY ACCURACY OF TRAINED MODEL\n",
    "        text_line = str(hyper_params) + \",accuracy:\" + str(result[1])  + \",validation:\" + str(validation[1]) + '\\n' \n",
    "        print(text_line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.quantize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        validation = model.test(validation_data_path)\n",
    "        \n",
    "        # DISPLAY ACCURACY OF TRAINED MODEL\n",
    "        text_line = str(hyper_params) + \",accuracy:\" + str(result[1])  + \",validation:\" + str(validation[1]) + '\\n' \n",
    "        print(text_line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['offensive'].value_counts().sort_index().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(\"shut up  german hillary  before i slap your canadian girlfriend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text_corrected'].str.len().plot.hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
